{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To do: #\n",
    "\n",
    "# Find out coefs/features. Figure out how to get model into live algo.\n",
    "# Figure out how to parallelize this, and do it with all top stocks.\n",
    "# Try this with out-of-the-way shit.\n",
    "# Try with crypto.\n",
    "# Cross-reference with classifier loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:70% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:70% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import fix_yahoo_finance as yf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "from datetime import timedelta\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor, AdaBoostRegressor, RandomForestRegressor, BaggingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set params here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks = ['CHK', 'IGC', 'WFT', 'RAD', 'SHLD', 'JCP', 'ABEV']\n",
    "\n",
    "start = '2000-1-1'\n",
    "end = '2018-8-1'\n",
    "\n",
    "rolling_avg = [5, 10, 50, 100]\n",
    "\n",
    "forward_rets = [20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHK\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Getting fwd_ret_20 results...\n",
      "IGC\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Getting fwd_ret_20 results...\n",
      "WFT\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Getting fwd_ret_20 results...\n",
      "RAD\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Getting fwd_ret_20 results...\n",
      "SHLD\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Getting fwd_ret_20 results...\n",
      "JCP\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Getting fwd_ret_20 results...\n",
      "ABEV\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Getting fwd_ret_20 results...\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "for stock in stocks:\n",
    "    \n",
    "    print(stock)\n",
    "    \n",
    "    try:\n",
    "        data = yf.download(stock, start, end)\n",
    "    \n",
    "        data['pct_change'] = data['Adj Close'].pct_change()\n",
    "\n",
    "        data['htc'] = (data['High'] - data['Close']) / (data['High'] - data['Low'])\n",
    "        data['ltc'] = (data['Close'] - data['Low']) / (data['High'] - data['Low'])\n",
    "\n",
    "        ########################\n",
    "        ### Rolling averages ###\n",
    "        ########################\n",
    "\n",
    "        for i in rolling_avg:\n",
    "\n",
    "            # ema, dist from ema\n",
    "\n",
    "            ema = data['Close'].ewm(span=i, min_periods=i, adjust=False).mean()\n",
    "            data['ema_' + str(i)] = ema\n",
    "            data['df_ema_' + str(i)] = (data['Close'] - ema) / data['Close']\n",
    "\n",
    "            # dist (mean, std, skew)\n",
    "\n",
    "            data['change_mean_' + str(i)] = data['pct_change'].ewm(span=i, min_periods=i, adjust=False).mean()\n",
    "            data['change_std_' + str(i)] = data['pct_change'].ewm(span=i, min_periods=i, adjust=False).std()\n",
    "            data['change_skew_' + str(i)] = data['pct_change'].rolling(window=i).skew()\n",
    "\n",
    "            # add ratio dists (mean, std, skew) here\n",
    "\n",
    "            data['htc_' + str(i)] = data['htc'].ewm(span=i, min_periods=i, adjust=False).mean()\n",
    "            data['ltc_' + str(i)] = data['ltc'].ewm(span=i, min_periods=i, adjust=False).mean()\n",
    "\n",
    "        data = data.fillna(0)\n",
    "\n",
    "        #######################\n",
    "        ### Forward returns ###\n",
    "        #######################\n",
    "\n",
    "        for forward in forward_rets:\n",
    "\n",
    "            #print('Getting targets for ' + str(forward) + ' days...')\n",
    "\n",
    "            # for the date, get the forward\n",
    "\n",
    "            ret_list = []\n",
    "\n",
    "            for date in range(len(data)):\n",
    "\n",
    "                # get the return amt close of date+foward\n",
    "\n",
    "                try:\n",
    "                    forward_ret = data.iloc[date+forward]['Adj Close']\n",
    "                    ret_list.append((forward_ret - data.iloc[date]['Adj Close']) / data.iloc[date]['Adj Close'])\n",
    "                except:\n",
    "                    ret_list.append(0)\n",
    "\n",
    "            data['fwd_ret_' + str(forward)] = ret_list\n",
    "\n",
    "        ###################\n",
    "        ### Set cutoffs ###\n",
    "        ###################\n",
    "\n",
    "        front_cutoff = max(rolling_avg)\n",
    "        back_cutoff = max(forward_rets)\n",
    "        data = data[front_cutoff:-back_cutoff]\n",
    "\n",
    "        ############################\n",
    "        ### Features and targets ###\n",
    "        ############################\n",
    "\n",
    "        features = [x for x in data.columns[5:] if 'fwd' not in x]\n",
    "        targets = [x for x in data.columns if 'fwd' in x]\n",
    "\n",
    "        ########################\n",
    "        ### Get the results! ###\n",
    "        ########################\n",
    "\n",
    "        for target in targets:\n",
    "\n",
    "            try:\n",
    "\n",
    "                print('Getting ' + str(target) + ' results...')\n",
    "\n",
    "                X = data[features]\n",
    "                y = data[target]\n",
    "\n",
    "                X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42) \n",
    "\n",
    "                pf = PolynomialFeatures(include_bias=False) \n",
    "                X_poly_train = pf.fit_transform(X_train)         \n",
    "                cols = pf.get_feature_names(features)\n",
    "                train_df = pd.DataFrame(X_poly_train, columns=cols)\n",
    "\n",
    "                pf = PolynomialFeatures(include_bias=False)\n",
    "                X_poly_test = pf.fit_transform(X_test)    \n",
    "                test_df = pd.DataFrame(X_poly_test, columns=cols)\n",
    "\n",
    "                ss = StandardScaler()\n",
    "                train_scaled = pd.DataFrame(ss.fit_transform(train_df), columns=train_df.columns)\n",
    "\n",
    "                ss = StandardScaler()\n",
    "                test_scaled = pd.DataFrame(ss.fit_transform(test_df), columns=train_df.columns)\n",
    "\n",
    "                rf = RandomForestRegressor()\n",
    "                rf.fit(train_scaled, y_train)\n",
    "                rf_res = {\n",
    "                    'stock': stock,\n",
    "                    'model': 'RandomForest',\n",
    "                    'train_score': rf.score(train_scaled, y_train),\n",
    "                    'test_score': rf.score(test_scaled, y_test),\n",
    "                    'target': target\n",
    "                }\n",
    "                results.append(rf_res)\n",
    "                \n",
    "#                 svr = SVR() # kernel\n",
    "#                 svr.fit(train_scaled, y_train)\n",
    "#                 svr_res = {\n",
    "#                     'stock': stock,\n",
    "#                     'model': 'SVR',\n",
    "#                     'train_score': svr.score(train_scaled, y_train),\n",
    "#                     'test_score': svr.score(test_scaled, y_test),\n",
    "#                     'target': target\n",
    "#                 }\n",
    "#                 results.append(svr_res)\n",
    "                \n",
    "#                 svr = SVR(kernel='linear') # kernel\n",
    "#                 svr.fit(train_scaled, y_train)\n",
    "#                 svr_res_l = {\n",
    "#                     'stock': stock,\n",
    "#                     'model': 'SVR_linear',\n",
    "#                     'train_score': svr.score(train_scaled, y_train),\n",
    "#                     'test_score': svr.score(test_scaled, y_test),\n",
    "#                     'target': target\n",
    "#                 }\n",
    "#                 results.append(svr_res_l)\n",
    "                \n",
    "#                 svr = SVR(kernel='poly') # kernel\n",
    "#                 svr.fit(train_scaled, y_train)\n",
    "#                 svr_res_p = {\n",
    "#                     'stock': stock,\n",
    "#                     'model': 'SVR_poly',\n",
    "#                     'train_score': svr.score(train_scaled, y_train),\n",
    "#                     'test_score': svr.score(test_scaled, y_test),\n",
    "#                     'target': target\n",
    "#                 }\n",
    "#                 results.append(svr_res_p)\n",
    "\n",
    "                gbc = GradientBoostingRegressor()\n",
    "                gbc.fit(train_scaled, y_train)\n",
    "                gbc_res = {\n",
    "                    'stock': stock,\n",
    "                    'model': 'GradientBoost',\n",
    "                    'train_score': gbc.score(train_scaled, y_train),\n",
    "                    'test_score': gbc.score(test_scaled, y_test),\n",
    "                    'target': target\n",
    "                }\n",
    "                results.append(gbc_res)\n",
    "\n",
    "                ada = AdaBoostRegressor()\n",
    "                ada.fit(train_scaled, y_train)\n",
    "                ada_res = {\n",
    "                    'stock': stock,\n",
    "                    'model': 'AdaBoost',\n",
    "                    'train_score': ada.score(train_scaled, y_train),\n",
    "                    'test_score': ada.score(test_scaled, y_test),\n",
    "                    'target': target\n",
    "                }\n",
    "                results.append(ada_res)\n",
    "\n",
    "                dt = DecisionTreeRegressor()\n",
    "                dt.fit(train_scaled, y_train)\n",
    "                dt_res = {\n",
    "                    'stock': stock,\n",
    "                    'model': 'DecisionTree',\n",
    "                    'train_score': dt.score(train_scaled, y_train),\n",
    "                    'test_score': dt.score(test_scaled, y_test),\n",
    "                    'target': target\n",
    "                }\n",
    "                results.append(dt_res)\n",
    "\n",
    "                bag = BaggingRegressor()\n",
    "                bag.fit(train_scaled, y_train)\n",
    "                bag_res = {\n",
    "                    'stock': stock,\n",
    "                    'model': 'Bagging',\n",
    "                    'train_score': bag.score(train_scaled, y_train),\n",
    "                    'test_score': bag.score(test_scaled, y_test),\n",
    "                    'target': target\n",
    "                }\n",
    "                results.append(bag_res)\n",
    "\n",
    "            except:\n",
    "                print('Exception w/results loop: ' + str(stock) + ' ' + str(target))\n",
    "                \n",
    "                results = pd.DataFrame(results)\n",
    "                \n",
    "                results.to_csv('results_.csv')\n",
    "                \n",
    "    except:\n",
    "        print('Exception w/YF downloader: ' + str(stock))\n",
    "\n",
    "results = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>stock</th>\n",
       "      <th>target</th>\n",
       "      <th>test_score</th>\n",
       "      <th>train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>CHK</td>\n",
       "      <td>fwd_ret_20</td>\n",
       "      <td>0.776285</td>\n",
       "      <td>0.956274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bagging</td>\n",
       "      <td>CHK</td>\n",
       "      <td>fwd_ret_20</td>\n",
       "      <td>0.770463</td>\n",
       "      <td>0.956780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>RAD</td>\n",
       "      <td>fwd_ret_20</td>\n",
       "      <td>0.720245</td>\n",
       "      <td>0.954543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Bagging</td>\n",
       "      <td>RAD</td>\n",
       "      <td>fwd_ret_20</td>\n",
       "      <td>0.690707</td>\n",
       "      <td>0.957634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>JCP</td>\n",
       "      <td>fwd_ret_20</td>\n",
       "      <td>0.645485</td>\n",
       "      <td>0.944911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>GradientBoost</td>\n",
       "      <td>RAD</td>\n",
       "      <td>fwd_ret_20</td>\n",
       "      <td>0.643746</td>\n",
       "      <td>0.743917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Bagging</td>\n",
       "      <td>JCP</td>\n",
       "      <td>fwd_ret_20</td>\n",
       "      <td>0.637795</td>\n",
       "      <td>0.948005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Bagging</td>\n",
       "      <td>WFT</td>\n",
       "      <td>fwd_ret_20</td>\n",
       "      <td>0.636579</td>\n",
       "      <td>0.942924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GradientBoost</td>\n",
       "      <td>CHK</td>\n",
       "      <td>fwd_ret_20</td>\n",
       "      <td>0.630283</td>\n",
       "      <td>0.744982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>WFT</td>\n",
       "      <td>fwd_ret_20</td>\n",
       "      <td>0.620874</td>\n",
       "      <td>0.940030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>SHLD</td>\n",
       "      <td>fwd_ret_20</td>\n",
       "      <td>0.600769</td>\n",
       "      <td>0.950663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Bagging</td>\n",
       "      <td>ABEV</td>\n",
       "      <td>fwd_ret_20</td>\n",
       "      <td>0.580919</td>\n",
       "      <td>0.970287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>RAD</td>\n",
       "      <td>fwd_ret_20</td>\n",
       "      <td>0.574274</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>ABEV</td>\n",
       "      <td>fwd_ret_20</td>\n",
       "      <td>0.571670</td>\n",
       "      <td>0.970725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>CHK</td>\n",
       "      <td>fwd_ret_20</td>\n",
       "      <td>0.540248</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>GradientBoost</td>\n",
       "      <td>WFT</td>\n",
       "      <td>fwd_ret_20</td>\n",
       "      <td>0.518371</td>\n",
       "      <td>0.651818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>GradientBoost</td>\n",
       "      <td>JCP</td>\n",
       "      <td>fwd_ret_20</td>\n",
       "      <td>0.495504</td>\n",
       "      <td>0.686112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Bagging</td>\n",
       "      <td>SHLD</td>\n",
       "      <td>fwd_ret_20</td>\n",
       "      <td>0.490795</td>\n",
       "      <td>0.949337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>GradientBoost</td>\n",
       "      <td>ABEV</td>\n",
       "      <td>fwd_ret_20</td>\n",
       "      <td>0.479434</td>\n",
       "      <td>0.758583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>RAD</td>\n",
       "      <td>fwd_ret_20</td>\n",
       "      <td>0.446405</td>\n",
       "      <td>0.426769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>CHK</td>\n",
       "      <td>fwd_ret_20</td>\n",
       "      <td>0.416482</td>\n",
       "      <td>0.464864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>GradientBoost</td>\n",
       "      <td>SHLD</td>\n",
       "      <td>fwd_ret_20</td>\n",
       "      <td>0.406112</td>\n",
       "      <td>0.719098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>ABEV</td>\n",
       "      <td>fwd_ret_20</td>\n",
       "      <td>0.319298</td>\n",
       "      <td>0.512550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>JCP</td>\n",
       "      <td>fwd_ret_20</td>\n",
       "      <td>0.269793</td>\n",
       "      <td>0.337268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>WFT</td>\n",
       "      <td>fwd_ret_20</td>\n",
       "      <td>0.198595</td>\n",
       "      <td>0.251894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>JCP</td>\n",
       "      <td>fwd_ret_20</td>\n",
       "      <td>0.184622</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>WFT</td>\n",
       "      <td>fwd_ret_20</td>\n",
       "      <td>0.171587</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>SHLD</td>\n",
       "      <td>fwd_ret_20</td>\n",
       "      <td>0.168470</td>\n",
       "      <td>0.401055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>SHLD</td>\n",
       "      <td>fwd_ret_20</td>\n",
       "      <td>0.148233</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>ABEV</td>\n",
       "      <td>fwd_ret_20</td>\n",
       "      <td>0.098963</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>IGC</td>\n",
       "      <td>fwd_ret_20</td>\n",
       "      <td>0.017747</td>\n",
       "      <td>0.422903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GradientBoost</td>\n",
       "      <td>IGC</td>\n",
       "      <td>fwd_ret_20</td>\n",
       "      <td>-0.335649</td>\n",
       "      <td>0.822274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>IGC</td>\n",
       "      <td>fwd_ret_20</td>\n",
       "      <td>-1.791484</td>\n",
       "      <td>0.943315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Bagging</td>\n",
       "      <td>IGC</td>\n",
       "      <td>fwd_ret_20</td>\n",
       "      <td>-3.311145</td>\n",
       "      <td>0.942543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>IGC</td>\n",
       "      <td>fwd_ret_20</td>\n",
       "      <td>-3.312046</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            model stock      target  test_score  train_score\n",
       "0    RandomForest   CHK  fwd_ret_20    0.776285     0.956274\n",
       "4         Bagging   CHK  fwd_ret_20    0.770463     0.956780\n",
       "15   RandomForest   RAD  fwd_ret_20    0.720245     0.954543\n",
       "19        Bagging   RAD  fwd_ret_20    0.690707     0.957634\n",
       "25   RandomForest   JCP  fwd_ret_20    0.645485     0.944911\n",
       "16  GradientBoost   RAD  fwd_ret_20    0.643746     0.743917\n",
       "29        Bagging   JCP  fwd_ret_20    0.637795     0.948005\n",
       "14        Bagging   WFT  fwd_ret_20    0.636579     0.942924\n",
       "1   GradientBoost   CHK  fwd_ret_20    0.630283     0.744982\n",
       "10   RandomForest   WFT  fwd_ret_20    0.620874     0.940030\n",
       "20   RandomForest  SHLD  fwd_ret_20    0.600769     0.950663\n",
       "34        Bagging  ABEV  fwd_ret_20    0.580919     0.970287\n",
       "18   DecisionTree   RAD  fwd_ret_20    0.574274     1.000000\n",
       "30   RandomForest  ABEV  fwd_ret_20    0.571670     0.970725\n",
       "3    DecisionTree   CHK  fwd_ret_20    0.540248     1.000000\n",
       "11  GradientBoost   WFT  fwd_ret_20    0.518371     0.651818\n",
       "26  GradientBoost   JCP  fwd_ret_20    0.495504     0.686112\n",
       "24        Bagging  SHLD  fwd_ret_20    0.490795     0.949337\n",
       "31  GradientBoost  ABEV  fwd_ret_20    0.479434     0.758583\n",
       "17       AdaBoost   RAD  fwd_ret_20    0.446405     0.426769\n",
       "2        AdaBoost   CHK  fwd_ret_20    0.416482     0.464864\n",
       "21  GradientBoost  SHLD  fwd_ret_20    0.406112     0.719098\n",
       "32       AdaBoost  ABEV  fwd_ret_20    0.319298     0.512550\n",
       "27       AdaBoost   JCP  fwd_ret_20    0.269793     0.337268\n",
       "12       AdaBoost   WFT  fwd_ret_20    0.198595     0.251894\n",
       "28   DecisionTree   JCP  fwd_ret_20    0.184622     1.000000\n",
       "13   DecisionTree   WFT  fwd_ret_20    0.171587     1.000000\n",
       "22       AdaBoost  SHLD  fwd_ret_20    0.168470     0.401055\n",
       "23   DecisionTree  SHLD  fwd_ret_20    0.148233     1.000000\n",
       "33   DecisionTree  ABEV  fwd_ret_20    0.098963     1.000000\n",
       "7        AdaBoost   IGC  fwd_ret_20    0.017747     0.422903\n",
       "6   GradientBoost   IGC  fwd_ret_20   -0.335649     0.822274\n",
       "5    RandomForest   IGC  fwd_ret_20   -1.791484     0.943315\n",
       "9         Bagging   IGC  fwd_ret_20   -3.311145     0.942543\n",
       "8    DecisionTree   IGC  fwd_ret_20   -3.312046     1.000000"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# results = pd.DataFrame(results)\n",
    "results.sort_values(by='test_score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
